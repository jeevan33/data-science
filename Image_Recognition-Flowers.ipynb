{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom PIL import Image\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport shutil\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(tf.__version__)\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%bash\nls -lrt ../input/flowers/flowers/daisy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Where do we start!?\n# 1. Access images\n# 2. Load images, and check on how they look (a sample set) (<Create a function>)\n# 3. Split dataset (<Create a function>)\n# 4. Preprocessing:\n#  a. Resize images to a standard size\n#  b. Apply a few transforms on the loaded standard size images\n# 4. Convert image into a format that can be fed into a CNN network\n# 5. Train model\n# 6. Test model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to show a sample of the flowers\ndef show_samples(directory):\n    lstImages = os.listdir(directory)\n    print('Number of Images {}'.format(len(lstImages)))\n    k = 0\n    for i in range(4):\n        f, ax = plt.subplots(1, 4, figsize = (15, 15))\n        for j in range(4):\n            img = Image.open(directory+lstImages[k])\n            img = img.resize((300, 300))\n            ax[j].imshow(img)\n            k = k + 1\n\n        plt.show()\n        time.sleep(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to split dataset (into Train and Test datasets)\ndef create_test_train_split(rootDir):\n    # Remove directories if they already exist\n    if 'Train' in os.listdir():\n        shutil.rmtree('Train')\n    if 'Test' in os.listdir():\n        shutil.rmtree('Test')\n        \n    # Create two different directories to hold Test and Train images\n    os.mkdir('Train', 777)\n    os.mkdir('Test', 777)\n    \n    # Determine subdirectories in the source directory\n    folders = os.listdir(rootDir)\n    \n    # Create as many subdirectories in the New folder structure as in the source structure\n    for r in range(len(folders)):\n        # Determine file names in the source\n        path = rootDir + folders[r] + '/'\n        lstFiles = os.listdir(path)\n    \n        testFlowers = []\n        trainFlowers = []\n        # Creation of new subdirectories\n        os.mkdir('Test/'+folders[r])\n        os.mkdir('Train/'+folders[r])\n        \n        # Pick each image from the source directory and copy it into the destination\n        for i in range(len(lstFiles)):\n            # Only '.jpg' images are being considered for this model\n            if '.jpg' not in lstFiles[i]:\n                continue\n            else:\n                # First 80% files being marked for training\n                if i < int(len(lstFiles) * 0.8):\n                    testFlowers.append(lstFiles[i])\n                    shutil.copy(path+lstFiles[i], 'Train/'+folders[r]+'/')\n                # Next 20% for testing\n                else:\n                    trainFlowers.append(lstFiles[i])\n                    shutil.copy(path+lstFiles[i], 'Test/'+folders[r]+'/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fixedPath = '../input/flowers/flowers/'\nflowerType = 'tulip/' # Input in lower letters\ntargetDir = fixedPath + flowerType","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_samples(targetDir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"create_test_train_split(fixedPath)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"-----------------------------------------------------MODEL TRAINING--------------------------------------------------"},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_images(HEIGHT, WIDTH, MODE):\n    # Initialize the first element of our array with zeros\n    arrImg = np.zeros(HEIGHT*WIDTH*3)\n    # Reshape it to (1, HEIGHT, WIDTH, 3). The first dimension will be the image count\n    arrImg = arrImg.reshape((1, HEIGHT, WIDTH, 3))\n    # We will delete this first element at a later point in time\n\n    # The first folder\n    folder0 = MODE + '/'\n    # Second folder\n    folders1 = os.listdir(folder0)\n    folders1.sort()\n    \n    lstLabel = []\n    global flower_type_mapping\n    flower_type_mapping = {}\n    flower_type = 0\n    # There will be multiple second folders\n    for f in folders1:\n        folder1 = f + '/'\n        # There will be multiple image files\n        files = os.listdir(folder0+folder1)\n        flower_type_mapping[flower_type] = f\n\n        # Load each image file and convert it into a numpy array\n        for i in files:\n            lstLabel.append(flower_type)\n            # Resize image as we load it\n            img = Image.open(folder0+folder1+i).resize((HEIGHT, WIDTH))\n            # Change dimension of the numpy array from (HEIGHT, WIDTH, 3) to (1, HEIGHT, WIDTH, 3)\n            # The way np.append works, its important to mention \"axis  = 0\"\n            arrImg = np.append(arrImg, np.expand_dims(np.asarray(img), axis = 0), axis = 0)\n            \n        flower_type = flower_type + 1\n\n    arrLabel = np.array(lstLabel)\n    # Remove the first dummy value in our array\n    arrImg = np.delete(arrImg, 0, axis = 0)\n    \n    return arrImg, arrLabel","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setting Height and Width to 28 for testing, since 299 was taking a long time\n# May be with better hardware a comparison can be made as to what happens with 299 pixels\nHEIGHT = 28\nWIDTH = 28\n\n# Mode is case sensitive. It takes either \"Train\" or \"Test\"\nMODE = 'Train'\nx_images, y_labels = load_images(HEIGHT, WIDTH, MODE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x_images.shape)\nprint(y_labels.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.models.Sequential()\nmodel.add(tf.keras.layers.Conv2D(filters = 10, kernel_size = (3, 3), padding = 'same', activation = tf.nn.relu))\nmodel.add(tf.keras.layers.MaxPool2D(pool_size = (2, 2)))\nmodel.add(tf.keras.layers.Conv2D(filters = 20, kernel_size = (3, 3), padding = 'same', activation = tf.nn.relu))\nmodel.add(tf.keras.layers.MaxPool2D(pool_size = (2, 2)))\n\nmodel.add(tf.keras.layers.Flatten())\n\nmodel.add(tf.keras.layers.Dense(256, activation = tf.nn.relu))\nmodel.add(tf.keras.layers.Dropout(rate = 0.25))\nmodel.add(tf.keras.layers.Dense(5, activation = tf.nn.softmax))\n\nmodel.compile(loss = 'categorical_crossentropy', optimizer = 'SGD')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(x_images, y_labels, batch_size = 32, epochs = 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MODE = 'Test'\nx_images, y_labels = load_images(HEIGHT, WIDTH, MODE)\nprint(x_images.shape)\nprint(y_labels.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = model.evaluate(x_images, y_labels, batch_size = 32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correct_prediction = []\nwrong_prediction = []\nfor i in range(len(x_images)):\n    sample = np.expand_dims(x_images[i], axis = 0)\n    prediction = model.predict(sample)\n    prediction = prediction.reshape(5,)\n    lst_prediction = prediction.astype(int).tolist()\n    \n    if lst_prediction.index(1) == y_labels[i]:\n        correct_prediction.append(1)\n    else:\n        wrong_prediction.append(0)\n    \nprint('Number of correct predictions: {}'.format(len(correct_prediction)))\nprint('Number of wrong predictions: {}'.format(len(wrong_prediction)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls Test/\nlen(os.listdir('Train/daisy/'))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}