{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport shutil\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# SECTION: What do we have here!?\n\n# Loading the dataset\nReviewsFile = '../input/googleplaystore_user_reviews.csv'\nPlayStoreFile = '../input/googleplaystore.csv'\ndfReviews = pd.read_csv(ReviewsFile)\ndfPlayStore = pd.read_csv(PlayStoreFile)\n\nprint('Reviews Dataset size: {}'.format(len(dfReviews)))\nprint('PlayStore Dataset size: {}'.format(len(dfPlayStore)))\nprint('\\n')\nprint(dfReviews.info())\nprint('\\n')\nprint(dfPlayStore.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# SECTION: Creating one single Dataframe with all required columns\n\n# INTENT:\n# 1. Let us have 'Rating' as the label\n# 2. The goal will be to, provided the following information, predict rating:\n#   a. Reviews\n#   b. Installs\n#   c. Genres (For a more complex version)\n\n# dfReviews is not of any particular use considering the above intent\n# Modifying dfPlayStore as required\n\ndfPlayStore.drop(columns = ['App', 'Category', 'Size',\\\n                            'Type', 'Price', 'Content Rating',\\\n                            'Last Updated', 'Current Ver', 'Android Ver'] , axis = 1, inplace = True)\ndfPlayStore[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the values against 'Installs' column\ndfPlayStore.groupby('Installs').count()\n\n# There is an unwanted value called 'Free'. Remove it.\ndfPlayStore = dfPlayStore[(dfPlayStore['Installs'] != 'Free')]\n\n# Length of 'Ratings' column\nlen(dfPlayStore['Rating'])\n# Length of 'Ratings' column without null values\ndfPlayStore['Rating'].count()\n# So, quiet a few rows with null ratings. Remove them.\ndfPlayStore.dropna(axis = 0, subset = ['Rating'], inplace = True, how = 'any')\n\n# Count of records in the Dataframe now\nlen(dfPlayStore)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# SECTION: Split Dataset for training, evaluation and testing\n\n#SUB SECTION: Using feature 'Installs' for splitting the dataset. So, create hashs of its values.\n# Extract all the unique 'Installs' values\ntempDf = dfPlayStore.groupby('Installs').count()\ninstallsLst = list(tempDf.index)\n\n# Create a new Dataframe that will hold Hash values of 'Installs'\ninstalls = pd.DataFrame(data = installsLst, columns = ['Installs'])\ninstalls['Hash'] = [hash(installs.iloc[i]['Installs']) for i in range(len(installs))]\n\ninstalls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# SUB SECTION: Mege Hash values with the original DataFrame.\ndfPlayStore = pd.merge(dfPlayStore, installs, left_on = 'Installs', right_on = 'Installs', how = 'inner')\ndfPlayStore","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a new DF that will tell us at what number to stop splitting on each Hash value\nindividualHashSplit = dfPlayStore.groupby('Hash').count()['Rating'].values*.7\nindividualHashSplit = np.around(individualHashSplit)\ndfIndividualHashSplit = pd.DataFrame(data = individualHashSplit, columns = ['Split'])\ndfIndividualHashSplit['Hash'] = dfPlayStore.groupby('Hash').count()['Rating'].index\ndfIndividualHashSplit['Total Records'] = dfPlayStore.groupby('Hash').count()['Rating'].values\n\ndfPlayStore","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a dictionary of Hashes and values\n# We go on decrementing the values during splitting of the dataset\nhashTreshDict = {}\nfor i in range(len(dfIndividualHashSplit)):\n    # Directly doing an iloc on the Data Frame is converting 'Hash' column to float\n    # So, the below workaround instead\n    hashSeries = dfIndividualHashSplit['Hash']\n    hashVal = hashSeries.iloc[i]\n    \n    splitVal = dfIndividualHashSplit.iloc[i]['Split']\n    hashTreshDict[hashVal] = splitVal\n\n#Initialize all variables that we require during splitting\ntestDFDict = {}\ntrainDFDict = {}\ntestKey = 0\ntrainKey = 0\n\narrRating_Test = np.array([])\narrReviews_Test = np.array([])\narrInstalls_Test = np.array([])\narrGenres_Test = np.array([])\narrHash_Test = np.array([])\n\narrRating_Train = np.array([])\narrReviews_Train = np.array([])\narrInstalls_Train = np.array([])\narrGenres_Train = np.array([])\narrHash_Train = np.array([])\n\n# Do the actual splitting\nfor i in range(len(dfPlayStore)):\n    # First of all, get the hash value\n    getHash = dfPlayStore.iloc[i]['Hash']\n\n    # Decrement count from the dictionary we are using for tracking\n    hashTreshDict[getHash] = hashTreshDict[getHash] - 1\n    \n    # Create numpy arrays for Test Dataset\n    if hashTreshDict[getHash] < 0:\n        arrRating_Test = np.append(arrRating_Test, dfPlayStore.iloc[i]['Rating'])\n        arrReviews_Test = np.append(arrReviews_Test, dfPlayStore.iloc[i]['Reviews'])\n        arrInstalls_Test = np.append(arrInstalls_Test, dfPlayStore.iloc[i]['Installs'])\n        arrGenres_Test = np.append(arrGenres_Test, dfPlayStore.iloc[i]['Genres'])\n        arrHash_Test = np.append(arrHash_Test, dfPlayStore.iloc[i]['Hash'])\n        testKey = testKey + 1\n    # Create numpy arrays for Train Dataset\n    else:\n        arrRating_Train = np.append(arrRating_Train, dfPlayStore.iloc[i]['Rating'])\n        arrReviews_Train = np.append(arrReviews_Train, dfPlayStore.iloc[i]['Reviews'])\n        arrInstalls_Train = np.append(arrInstalls_Train, dfPlayStore.iloc[i]['Installs'])\n        arrGenres_Train = np.append(arrGenres_Train, dfPlayStore.iloc[i]['Genres'])\n        arrHash_Train = np.append(arrHash_Train, dfPlayStore.iloc[i]['Hash'])\n        trainKey = trainKey + 1\n\n# Create Test DataFrame\ntestDFDict['Rating'] = arrRating_Test\ntestDFDict['Reviews'] = arrReviews_Test\ntestDFDict['Installs'] = arrInstalls_Test\ntestDFDict['Genres'] = arrGenres_Test\ntestDFDict['Hash'] = arrHash_Test\ntestDFPlayStore = pd.DataFrame(testDFDict)\n\n# Create Train DataFrame\ntrainDFDict['Rating'] = arrRating_Train\ntrainDFDict['Reviews'] = arrReviews_Train\ntrainDFDict['Installs'] = arrInstalls_Train\ntrainDFDict['Genres'] = arrGenres_Train\ntrainDFDict['Hash'] = arrHash_Train\ntrainDFPlayStore = pd.DataFrame(trainDFDict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create Train and Test CSVs\ntestDFPlayStore.to_csv('test.csv')\ntrainDFPlayStore.to_csv('train.csv')\n!ls -lrt\n!head test.csv\n!head train.csv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i = 0\nreviewsFloat = np.array([])\nfor i in range(len(trainDFPlayStore['Reviews'])):\n    reviewsFloat = np.append(reviewsFloat, float(trainDFPlayStore['Reviews'][i]))\n\nreviewsFloat\ntrainDFPlayStore['ReviewsFloat'] = reviewsFloat\ntrainDFPlayStore[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create Input Function, feature tensors etc.\ntrainInputFunction = tf.estimator.inputs.pandas_input_fn(\n    x = trainDFPlayStore,\n    y= trainDFPlayStore['Rating'],\n    batch_size = 128,\n    num_epochs = 100,\n    shuffle = True,\n    num_threads=1\n)\n\ntestInputFunction = tf.estimator.inputs.pandas_input_fn(\n    x = testDFPlayStore,\n    y = None,\n    batch_size = 128,\n    shuffle = False,\n    num_threads = 1\n)\n\nratingT = tf.feature_column.numeric_column('Rating')\nreviewsT = tf.feature_column.numeric_column('ReviewsFloat')\ninstallsT = tf.feature_column.indicator_column('Installs')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# SECTION: Train a Linear Model\nOUTDIR = 'Trained-Linear'\nshutil.rmtree(OUTDIR, ignore_errors = True)\n\nmodel = tf.estimator.LinearRegressor(\n      feature_columns = [ratingT, reviewsT], model_dir = OUTDIR)\n\nmodel.train(input_fn = trainInputFunction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train a DNN Regressor\nOUTDIR = 'Trained-DNN'\nshutil.rmtree(OUTDIR, ignore_errors = True)\n\nEstimator_DNN = tf.estimator.DNNRegressor(\n    feature_columns = [ratingT, reviewsT],\n    model_dir = OUTDIR,\n    hidden_units=[8, 4]\n)\n\nEstimator_DNN.train(input_fn = trainInputFunction)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}