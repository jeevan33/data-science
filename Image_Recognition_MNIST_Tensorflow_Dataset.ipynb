{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image_Recognition-MNIST-Tensorflow_Dataset",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeRPvfnV3WmA",
        "colab_type": "code",
        "outputId": "26b77957-2c1f-4e98-c1aa-4a5f17980656",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "# Import all libraries\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as td\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "# Define variables/hyperparameters\n",
        "eager_execution = False\n",
        "batch_size = 32\n",
        "nclasses = 10\n",
        "num_epochs = 1\n",
        "# This should ideally depend on number of records in a dataset\n",
        "# But in Tensorflow 1.x there does not seem to be many good ways of determining it on the go\n",
        "steps_per_epoch = 25000 \n",
        "\n",
        "# To execute eagerly or not?\n",
        "if eager_execution == True:\n",
        "  # Enable eager execution\n",
        "  tf.enable_eager_execution()\n",
        "\n",
        "  # Checking eager execution\n",
        "  a = tf.constant([[1, 2],\n",
        "                   [3, 4]])\n",
        "  b = tf.constant([[1, 2],\n",
        "                  [3, 4]])\n",
        "  c = tf.add(a, b)\n",
        "  print(c)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0806 04:52:54.884473 140281936885632 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mS8g214N3iIM",
        "colab_type": "code",
        "outputId": "04b7e5b7-47d5-428e-c7fe-b929da301b23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "# Load MNIST Dataset\n",
        "#td.list_builders() # To check all available datasets\n",
        "mnist_dataset = td.load(name = 'mnist', split = 'train')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0806 04:52:55.257077 140281936885632 dataset_builder.py:439] Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2maKfdXgrACY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add the batch dimension to our dataset. Tensorflow expects Conv2D to have dimesions like this: (batch, height, width, channels)\n",
        "# So, induce the batch dimension\n",
        "def add_dimension(dataset_row):\n",
        "  dataset_row['image'] = tf.image.convert_image_dtype(dataset_row['image'], dtype = tf.float32)\n",
        "  dataset_row['image'] = tf.expand_dims(dataset_row['image'], axis = 0)\n",
        "  \n",
        "  dataset_row['label'] = tf.one_hot(dataset_row['label'], depth = 10, axis = 0)\n",
        "\n",
        "  return dataset_row\n",
        "\n",
        "# Larger function to accommodate all preprocessing\n",
        "def preprocess(dataset):\n",
        "  dataset = dataset.map(add_dimension)\n",
        "  dataset = dataset.shuffle(buffer_size = 10 * batch_size)\n",
        "  dataset = dataset.repeat(count = num_epochs)\n",
        "  \n",
        "  return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMFFPeOm98Kq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataset ready for training\n",
        "mnist_dataset = preprocess(mnist_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADAOZcJW7sIF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build model\n",
        "model = tf.keras.models.Sequential()\n",
        "#model.add(tf.keras.layers.InputLayer(input_shape = [28, 28, 1]))\n",
        "model.add(tf.keras.layers.Conv2D(filters = 10, kernel_size = 3, padding = 'same', activation = tf.nn.relu))\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size = 2))\n",
        "model.add(tf.keras.layers.Conv2D(filters = 20, kernel_size = 3, padding = 'same', activation = tf.nn.relu))\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size = 2))\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "model.add(tf.keras.layers.Dense(256, activation = tf.nn.relu))\n",
        "model.add(tf.keras.layers.Dropout(rate = 0.25))\n",
        "model.add(tf.keras.layers.Dense(10, activation = tf.nn.softmax))\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpZVNJgqCOqx",
        "colab_type": "code",
        "outputId": "db4bcad9-bbbc-4142-a696-f3b35b276dd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Check if Eager Execution is enabled or not\n",
        "if tf.executing_eagerly() == True:\n",
        "  print('Yes')\n",
        "else:\n",
        "  print('No')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6JmRRLf-7m_",
        "colab_type": "code",
        "outputId": "cfdd84ff-e12b-4a54-aa26-c7fddeb0149d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#https://github.com/tensorflow/tensorflow/issues/26658\n",
        "if tf.executing_eagerly() == True:\n",
        "  mnist_iterator = iter(mnist_dataset)\n",
        "  model.fit(x = next(mnist_iterator)['image'], y = next(mnist_iterator)['label'], batch_size = batch_size, epochs = num_epochs, steps_per_epoch = steps_per_epoch)\n",
        "else:\n",
        "  # make_one_shot_iterator() is DEPRECATED in TF 2.0\n",
        "  mnist_iterator = mnist_dataset.make_one_shot_iterator()\n",
        "  model.fit(x = mnist_iterator.get_next()['image'], y = mnist_iterator.get_next()['label'], batch_size = batch_size, epochs = num_epochs, steps_per_epoch = steps_per_epoch)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 117s 5ms/step - loss: 2.3031 - acc: 0.1091\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIjF1RhyBFFU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load Test Dataset\n",
        "mnist_test = td.load(name = 'mnist', split = 'test')\n",
        "mnist_test = preprocess(mnist_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZoKtyhsBcdH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if tf.executing_eagerly() == True:\n",
        "  mnist_iterator = iter(mnist_test)\n",
        "  metrics = model.evaluate(x = next(mnist_iterator)['image'], y = next(mnist_iterator)['label'], batch_size = batch_size, steps = None)\n",
        "else:\n",
        "  # make_one_shot_iterator() is DEPRECATED in TF 2.0\n",
        "  mnist_iterator = mnist_test.make_one_shot_iterator()\n",
        "  metrics = model.evaluate(x = mnist_iterator.get_next()['image'], y = mnist_iterator.get_next()['label'], batch_size = batch_size, steps = 2500)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDqleBeqCQHe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ANKoctmTQs97",
        "colab": {}
      },
      "source": [
        "model.predict(mnist_iterator.get_next()['image'], steps = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBhtDf2xBFWD",
        "colab_type": "text"
      },
      "source": [
        "------------------------------------------------------------------------------MISCELLANEOUS----------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtIgg-INSJ9a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check info about this dataset\n",
        "mnist_dataset_builder = td.builder('mnist')\n",
        "print(mnist_dataset_builder.info)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}